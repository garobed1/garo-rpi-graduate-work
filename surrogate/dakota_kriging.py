"""
Wrapper for the dakota/surfpack GP model, with option for gradient enhancement
"""
import numpy as np
import subprocess
from scipy import linalg

from smt.surrogate_models.surrogate_model import SurrogateModel
from smt.utils.kriging_utils import standardization

class DakotaKriging(SurrogateModel):

    name = "DakotaKriging"

    def _initialize(self):
        super(DakotaKriging, self)._initialize()
        declare = self.options.declare
        declare(
            "header",
            "py_dak_",
            types=(str),
            desc="prefix used for all files generated by this wrapper",
        )
        declare(
            "xlimits",
            types=np.ndarray,
            desc="Lower/upper bounds in each dimension - ndarray [nx, 2]",
        )
        declare(
            "implementation",
            "surfpack",
            types=(str),
            desc="which kriging implementation to use in Dakota, either default or surfpack",
        )
        declare(
            "use_derivatives",
            False,
            types=(bool),
            desc="use GEK, only for surfpack implementation"
        )
        declare(
            "trend",
            "linear",
            values=("constant", "linear", "reduced_quadratic" "quadratic"),
            desc="Regression function type",
            types=(str),
        )
        declare(
            "nugget",
            None,
            desc="Regression function type",
            types=(float),
        )
        declare(
            "optimization_method",
            "global",
            values=("global", "local", "sampling", "none"),
            desc="Hyperparameter optimization method",
            types=(str),
        )

        """
        Missing options:
        max_trials
        find_nugget
        correlation_lengths
        export_model
        import_model
        """

        self.supports["derivatives"] = True
        self.supports["output_derivatives"] = True
        self.supports["training_derivatives"] = True

    def _setup(self):
        options = self.options

        self.dakota_train_file   = self.options["header"] + "smt_train_surrogate.in"
        self.dakota_predict_file   = self.options["header"] + "smt_predict_surrogate.in"
        self.training_file = self.options["header"] + "smt_training.dat"
        self.eval_file     = self.options["header"] + "smt_evaluate.dat"
        self.surrogate_file= self.options["header"] + "smt_saved_surr"
        self.output_file   = self.options["header"] + "smt_output.dat"
        self.stdout_train_file   = self.options["header"] + "smt_stdout_train.dat"
        self.stderr_train_file   = self.options["header"] + "smt_stderr_train.dat"
        self.stdout_predict_file   = self.options["header"] + "smt_stdout_predict.dat"
        self.stderr_predict_file   = self.options["header"] + "smt_stderr_predict.dat"
 
        self.ndim = self.training_points[None][0][0].shape[1]
        self.xlimits = self.options["xlimits"]
        # write out options in the dakota input file

        # training and prediction files should be nearly identical

        # environment
        for file in [self.dakota_train_file, self.dakota_predict_file]:
            with open(file, 'w') as the_file:
                the_file.write('environment\n')
                the_file.write('  method_pointer = \'EvalSurrogate\'\n')
                the_file.write('  output_precision = 16\n')
                the_file.write('  tabular_data\n')
                the_file.write(f'    tabular_data_file = \'{self.output_file}\'\n')
                the_file.write(f'      freeform\n')
                the_file.write('\n')
            # method
                the_file.write('method\n')
                the_file.write('  id_method = \'EvalSurrogate\'\n')
                the_file.write('  model_pointer = \'SurrogateModel\'\n')
                the_file.write('  list_parameter_study\n')
                # if(file == self.dakota_train_file):
                #     the_file.write(f'    list_of_points = ')
                #     for i in range(self.ndim):
                #         the_file.write(f' {self.xlimits[i][0]} ')
                # else:
                the_file.write(f'    import_points_file \'{self.eval_file}\'\n')
                the_file.write('      freeform\n')
                the_file.write('\n')
            # model
                the_file.write('model\n')
                the_file.write('  id_model = \'SurrogateModel\'\n')
                the_file.write('  surrogate global\n')
                if(self.options["use_derivatives"]):
                    the_file.write("    use_derivatives\n")
                the_file.write(f'    gaussian_process {self.options["implementation"]}\n')
                the_file.write(f'      import_build_points \'{self.training_file}\'\n')
                the_file.write('        freeform\n')
                the_file.write('\n')
            # process model keywords in options
                the_file.write('      trend\n')
                the_file.write(f'        {self.options["trend"]}\n')
                if(self.options["nugget"]):
                    the_file.write('      nugget\n')
                    the_file.write(f'        {self.options["nugget"]}\n')
                the_file.write(f'      optimization_method = \'{self.options["optimization_method"]}\'\n')
                the_file.write('\n')
                if(file == self.dakota_train_file):
                    the_file.write('      export_model\n')

                else:
                    the_file.write('      import_model\n')
                the_file.write(f'        filename_prefix = \'{self.surrogate_file}\'\n')
                if(file == self.dakota_train_file):
                    the_file.write(f'        formats\n')
                    the_file.write(f'          binary_archive\n')
                else:                    
                    the_file.write(f'      binary_archive\n')           
                the_file.write('\n')
            # variables
                the_file.write('variables\n')
                the_file.write(f'  uniform_uncertain = {self.ndim}\n')
                the_file.write('    lower_bounds    = ')
                for i in range(self.ndim):
                    the_file.write(f' {self.xlimits[i][0]} ')
                the_file.write('\n')
                the_file.write('    upper_bounds    = ')
                for i in range(self.ndim):
                    the_file.write(f' {self.xlimits[i][1]} ')
                the_file.write('\n')
                the_file.write('    descriptors    = ')
                for i in range(self.ndim):
                    the_file.write(f' \'x{i}\' ')
                the_file.write('\n\n')
            # responses
                the_file.write('responses\n')
                the_file.write('  response_functions = 1\n')
                the_file.write('    descriptors = \'fn\'\n')
                # if(self.options["use_derivatives"]):
                #     the_file.write('  analytic_gradients\n')
                # else:
                the_file.write('  no_gradients\n')
                the_file.write('  no_hessians\n')


    def _new_train(self):
        
        # write the training data to a .dat file
        x = self.training_points[None][0][0]
        f = self.training_points[None][0][1]
        npts = x.shape[0]

        with open(self.training_file, 'w') as the_file:
            for i in range(npts):
                for j in range(self.ndim):
                    the_file.write(f' {x[i][j]}')
                the_file.write(f' {f[i][0]}')
                the_file.write('\n')

            # HOW TO DO THIS?
            if(self.options["use_derivatives"]):
                for i in range(npts):
                    the_file.write(f'[')
                    for j in range(self.ndim-1):
                        the_file.write(f'{self.training_points[None][j+1][1][i][0]} ')
                    the_file.write(f'{self.training_points[None][j+1][1][i][-1]}]\n')

        command = f'dakota -input {self.dakota_train_file} -no_input_echo'
        with open(self.stdout_train_file, "w") as file_out:
            with open(self.stderr_train_file, "w") as error_out:
                subprocess.call(command, shell=True, stdout=file_out, stderr=error_out)#, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True, shell=True)

    def _train(self):
        """
        Train the model
        """
        self._setup()
        self._new_train()

   
    def _predict_values(self, x):
        """
        Evaluates the model at a set of points.

        Parameters
        ----------
        x : np.ndarray [n_evals, dim]
            Evaluation point input variable values

        Returns
        -------
        y : np.ndarray
            Evaluation point output variable values
        """
        # write the prediction data to a .dat file
        npts = x.shape[0]
        with open(self.eval_file, 'w') as the_file:
            for i in range(npts):
                for j in range(self.ndim):
                    the_file.write(f'{x[i][j]} ')
                the_file.write('\n')

        command = f'dakota -input {self.dakota_predict_file} -no_input_echo'
        with open(self.stdout_predict_file, "w") as file_out:
            with open(self.stderr_predict_file, "w") as error_out:
                subprocess.call(command, shell=True, stdout=file_out, stderr=error_out)#, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True, shell=True)


        # read the output
        with open(self.output_file, 'r') as the_file:
            out = np.array([line.split() for line in list(the_file)])
        
        #subprocess.call(command2.split())
        out = out.astype(np.float)
        y = np.array([out[:,-1]])
        #import pdb; pdb.set_trace()
        return y

    #TODO: Need to implement this
    def _predict_derivatives(self, x, kx):
        """
        Evaluates the derivatives at a set of points.

        Parameters
        ---------
        x : np.ndarray [n_evals, dim]
            Evaluation point input variable values
        kx : int
            The 0-based index of the input variable with respect to which derivatives are desired.

        Returns
        -------
        y : np.ndarray
            Derivative values.
        """
        return 0

